{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Especially on Linux, gdxpds should be imported before pandas to avoid a library conflict. Also make sure your GAMS directory is listed in LD_LIBRARY_PATH.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from model import CRAB_Model\n",
    "seed_value = 12345678\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed=seed_value)\n",
    "import gdxpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = gdxpds.to_dataframes('results_ssp2_cba_noncoop_crab_in.gdx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inputs_crab = \"CRAB/Inputs/\"\n",
    "# load model inputs\n",
    "socio_economic_hh_attributes = pd.read_csv(path_inputs_crab + \"HH_attributes_us\")\n",
    "rice_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flood_prob</th>\n",
       "      <th>Worry</th>\n",
       "      <th>RE_elev</th>\n",
       "      <th>RE_wet</th>\n",
       "      <th>RE_dry</th>\n",
       "      <th>SE_elev</th>\n",
       "      <th>SE_wet</th>\n",
       "      <th>SE_dry</th>\n",
       "      <th>PC_elev</th>\n",
       "      <th>...</th>\n",
       "      <th>Social network</th>\n",
       "      <th>Education</th>\n",
       "      <th>Savings_norm</th>\n",
       "      <th>HH_sell_norm</th>\n",
       "      <th>t</th>\n",
       "      <th>OMEGA</th>\n",
       "      <th>CPC</th>\n",
       "      <th>Y</th>\n",
       "      <th>I</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>8.700181</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.206</td>\n",
       "      <td>29.000603</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.092</td>\n",
       "      <td>34.800723</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.400362</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.683</td>\n",
       "      <td>14.500301</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.799</td>\n",
       "      <td>43.500904</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.256</td>\n",
       "      <td>23.200482</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.600241</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.022</td>\n",
       "      <td>24.360506</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.926</td>\n",
       "      <td>14.500301</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Flood_prob  Worry  RE_elev    RE_wet    RE_dry  SE_elev  \\\n",
       "0              0        0.10    3.0      3.0  2.000000  1.333333      1.0   \n",
       "1              1        0.20    3.0      3.0  3.000000  3.000000      3.0   \n",
       "2              2        0.05    1.0      5.0  5.000000  5.000000      5.0   \n",
       "3              3        0.20    1.0      3.0  4.666667  3.000000      1.0   \n",
       "4              4        1.00    2.0      1.0  3.666667  3.333333      1.0   \n",
       "...          ...         ...    ...      ...       ...       ...      ...   \n",
       "4995        4995        0.30    3.0      4.0  4.000000  4.000000      1.0   \n",
       "4996        4996        0.20    2.0      5.0  4.333333  4.000000      5.0   \n",
       "4997        4997        0.00    2.0      1.0  4.000000  3.666667      1.0   \n",
       "4998        4998        0.01    3.0      4.0  4.666667  4.333333      3.0   \n",
       "4999        4999        0.00    1.0      3.0  3.333333  3.666667      1.0   \n",
       "\n",
       "        SE_wet    SE_dry  PC_elev  ...  Social network  Education  \\\n",
       "0     1.000000  1.000000      5.0  ...             1.0        2.0   \n",
       "1     3.000000  3.000000      3.0  ...             6.0        3.0   \n",
       "2     5.000000  5.000000      5.0  ...             0.0        4.0   \n",
       "3     1.000000  1.000000      5.0  ...             0.0        3.0   \n",
       "4     4.000000  4.000000      5.0  ...             0.0        3.0   \n",
       "...        ...       ...      ...  ...             ...        ...   \n",
       "4995  3.000000  2.000000      4.0  ...             3.0        4.0   \n",
       "4996  4.333333  4.000000      5.0  ...             2.0        3.0   \n",
       "4997  1.000000  1.000000      5.0  ...             3.0        2.0   \n",
       "4998  4.333333  4.333333      4.0  ...             2.0        3.0   \n",
       "4999  1.000000  1.000000      5.0  ...             6.0        2.0   \n",
       "\n",
       "      Savings_norm  HH_sell_norm  t  OMEGA        CPC   Y         I   C  \n",
       "0            0.168      8.700181  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "1            0.206     29.000603  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "2            4.092     34.800723  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "3            0.000     17.400362  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "4            0.683     14.500301  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "...            ...           ... ..    ...        ...  ..       ...  ..  \n",
       "4995         2.799     43.500904  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "4996         2.256     23.200482  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "4997         0.000     11.600241  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "4998         1.022     24.360506  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "4999         0.926     14.500301  2    NaN  39.249089 NaN  3.158033 NaN  \n",
       "\n",
       "[5000 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "socio_economic_hh_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/33/dr4cqnzj0597_7n7kbsrfht8cdq0jk/T/ipykernel_56822/1652757757.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['variable'] = i\n",
      "/var/folders/33/dr4cqnzj0597_7n7kbsrfht8cdq0jk/T/ipykernel_56822/1652757757.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['variable'] = i\n",
      "/var/folders/33/dr4cqnzj0597_7n7kbsrfht8cdq0jk/T/ipykernel_56822/1652757757.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['variable'] = i\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# get t to be used in the ABM\n",
    "t = socio_economic_hh_attributes['t'][0]\n",
    "#print('t is ddddd', t)\n",
    "# make list of variable of interests (omega, consumption, investment, expected damages etc) + for the regions of interest\n",
    "# iterate over them to get  values of interest\n",
    "# put together in a dataframe\n",
    "input_list = []\n",
    "variable_of_interest = ['OMEGA', 'C', 'Y']\n",
    "regions_of_interest = ['us']\n",
    "for i in variable_of_interest:\n",
    "    dataframe = dataframes[i]\n",
    "    dataframe['t'] = dataframe['t'].astype(int)\n",
    "    for j in regions_of_interest:\n",
    "        dataframe = dataframe.loc[(dataframe['t'] == t) & (dataframe['n'] == 'usa')]\n",
    "        dataframe['variable'] = i\n",
    "        input_list.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = pd.concat(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>n</th>\n",
       "      <th>Level</th>\n",
       "      <th>Marginal</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Scale</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000e+300</td>\n",
       "      <td>3.000000e+300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OMEGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "      <td>12.933791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>3.000000e+300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t    n      Level  Marginal          Lower          Upper  Scale variable\n",
       "54   2  usa   0.001135       0.0  4.000000e+300  3.000000e+300    1.0    OMEGA\n",
       "111  2  usa  12.933791       0.0   1.000000e-08  3.000000e+300    1.0        C\n",
       "111  2  usa  16.092273       0.0   0.000000e+00  3.000000e+300    1.0        Y"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# add 'Level' from input_list to socio_economic_hh_attributea, for each variable of interest\n",
    "for i in variable_of_interest:\n",
    "    variable = input_list.loc[input_list['variable'] == i]['Level']\n",
    "    socio_economic_hh_attributes[i] = variable.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flood_prob</th>\n",
       "      <th>Worry</th>\n",
       "      <th>RE_elev</th>\n",
       "      <th>RE_wet</th>\n",
       "      <th>RE_dry</th>\n",
       "      <th>SE_elev</th>\n",
       "      <th>SE_wet</th>\n",
       "      <th>SE_dry</th>\n",
       "      <th>PC_elev</th>\n",
       "      <th>...</th>\n",
       "      <th>Social network</th>\n",
       "      <th>Education</th>\n",
       "      <th>Savings_norm</th>\n",
       "      <th>HH_sell_norm</th>\n",
       "      <th>t</th>\n",
       "      <th>OMEGA</th>\n",
       "      <th>CPC</th>\n",
       "      <th>Y</th>\n",
       "      <th>I</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>8.700181</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.206</td>\n",
       "      <td>29.000603</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.092</td>\n",
       "      <td>34.800723</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.400362</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.683</td>\n",
       "      <td>14.500301</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.799</td>\n",
       "      <td>43.500904</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.256</td>\n",
       "      <td>23.200482</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.600241</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.022</td>\n",
       "      <td>24.360506</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.926</td>\n",
       "      <td>14.500301</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>39.249089</td>\n",
       "      <td>16.092273</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>12.933791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Flood_prob  Worry  RE_elev    RE_wet    RE_dry  SE_elev  \\\n",
       "0              0        0.10    3.0      3.0  2.000000  1.333333      1.0   \n",
       "1              1        0.20    3.0      3.0  3.000000  3.000000      3.0   \n",
       "2              2        0.05    1.0      5.0  5.000000  5.000000      5.0   \n",
       "3              3        0.20    1.0      3.0  4.666667  3.000000      1.0   \n",
       "4              4        1.00    2.0      1.0  3.666667  3.333333      1.0   \n",
       "...          ...         ...    ...      ...       ...       ...      ...   \n",
       "4995        4995        0.30    3.0      4.0  4.000000  4.000000      1.0   \n",
       "4996        4996        0.20    2.0      5.0  4.333333  4.000000      5.0   \n",
       "4997        4997        0.00    2.0      1.0  4.000000  3.666667      1.0   \n",
       "4998        4998        0.01    3.0      4.0  4.666667  4.333333      3.0   \n",
       "4999        4999        0.00    1.0      3.0  3.333333  3.666667      1.0   \n",
       "\n",
       "        SE_wet    SE_dry  PC_elev  ...  Social network  Education  \\\n",
       "0     1.000000  1.000000      5.0  ...             1.0        2.0   \n",
       "1     3.000000  3.000000      3.0  ...             6.0        3.0   \n",
       "2     5.000000  5.000000      5.0  ...             0.0        4.0   \n",
       "3     1.000000  1.000000      5.0  ...             0.0        3.0   \n",
       "4     4.000000  4.000000      5.0  ...             0.0        3.0   \n",
       "...        ...       ...      ...  ...             ...        ...   \n",
       "4995  3.000000  2.000000      4.0  ...             3.0        4.0   \n",
       "4996  4.333333  4.000000      5.0  ...             2.0        3.0   \n",
       "4997  1.000000  1.000000      5.0  ...             3.0        2.0   \n",
       "4998  4.333333  4.333333      4.0  ...             2.0        3.0   \n",
       "4999  1.000000  1.000000      5.0  ...             6.0        2.0   \n",
       "\n",
       "      Savings_norm  HH_sell_norm  t     OMEGA        CPC          Y         I  \\\n",
       "0            0.168      8.700181  2  0.001135  39.249089  16.092273  3.158033   \n",
       "1            0.206     29.000603  2  0.001135  39.249089  16.092273  3.158033   \n",
       "2            4.092     34.800723  2  0.001135  39.249089  16.092273  3.158033   \n",
       "3            0.000     17.400362  2  0.001135  39.249089  16.092273  3.158033   \n",
       "4            0.683     14.500301  2  0.001135  39.249089  16.092273  3.158033   \n",
       "...            ...           ... ..       ...        ...        ...       ...   \n",
       "4995         2.799     43.500904  2  0.001135  39.249089  16.092273  3.158033   \n",
       "4996         2.256     23.200482  2  0.001135  39.249089  16.092273  3.158033   \n",
       "4997         0.000     11.600241  2  0.001135  39.249089  16.092273  3.158033   \n",
       "4998         1.022     24.360506  2  0.001135  39.249089  16.092273  3.158033   \n",
       "4999         0.926     14.500301  2  0.001135  39.249089  16.092273  3.158033   \n",
       "\n",
       "              C  \n",
       "0     12.933791  \n",
       "1     12.933791  \n",
       "2     12.933791  \n",
       "3     12.933791  \n",
       "4     12.933791  \n",
       "...         ...  \n",
       "4995  12.933791  \n",
       "4996  12.933791  \n",
       "4997  12.933791  \n",
       "4998  12.933791  \n",
       "4999  12.933791  \n",
       "\n",
       "[5000 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "socio_economic_hh_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 10\n",
    "steps = 300\n",
    "#seeds = [69593830] \n",
    "seeds = [random.randint(1, seed_value ) for i in range(runs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variables = []\n",
    "macro_variables = []\n",
    "for i, seed in enumerate(seeds):\n",
    "    # print((\"Model initialized with \" + str(H) + \" Households\"))\n",
    "    print(\"Run num\", i, \"with random seed\", seed)\n",
    "    tic = time.time()\n",
    "    model = CRAB_Model(F1=125, F2=200, F3=300,H=5000, Exp = 500,RCP = 2.5, seed=seed, hh_cca = False,  insurance_hh= False, floods=False)\n",
    "    model.reset_randomizer(seed)\n",
    "    for j in range(steps):\n",
    "        print(\"#------------ step\", j+1, \"------------#\")\n",
    "        model.step()\n",
    "    toc = time.time()\n",
    "    runtime = toc - tic\n",
    "    # runtimes.append(runtime)\n",
    "    print(\"MODEL runtime: \" + str(runtime))\n",
    "    print()\n",
    "    # # --------\n",
    "    # # COMMENT:\n",
    "    # # Look into efficient output saving later\n",
    "    # # --------\n",
    "    macro_variable = model.datacollector.get_model_vars_dataframe()\n",
    "    # # Iteratively add dataframe to list\n",
    "    macro_variables.append(macro_variable)\n",
    "    micro_variable = model.datacollector.get_agent_vars_dataframe()\n",
    "    micro_variables.append(micro_variable)\n",
    "    #micro_variable = micro_variable.dropna()\n",
    "    # # micro_variable[[\"Demand coastal\", \"Demand Inland\"]] = pd.DataFrame(micro_variable.Real_demand_cap.to_list(), index=micro_variable.index)\n",
    "    # # micro_variable[[\"Competitiveness region 0\", \"Competitiveness region 1\", \"Competitiveness export\"]] = pd.DataFrame(micro_variable.Competitiveness.to_list(), index=micro_variable.index)\n",
    "    # # micro_variable[[\"MS region 0\", \"MS region 1\", \"MS export\"]] = pd.DataFrame(micro_variable.Ms.to_list(), index=micro_variable.index)\n",
    "    # # micro_variable[[\"Prod A\", \"Prod B\"]] = pd.DataFrame(micro_variable.Prod.to_list(), index=micro_variable.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_variable = model.datacollector.get_model_vars_dataframe()\n",
    "# # Iteratively add dataframe to list\n",
    "macro_variables.append(macro_variable)\n",
    "micro_variable = model.datacollector.get_agent_vars_dataframe()\n",
    "#micro_variable = micro_variable.dropna()\n",
    "\n",
    "# # micro_variable[[\"Demand coastal\", \"Demand Inland\"]] = pd.DataFrame(micro_variable.Real_demand_cap.to_list(), index=micro_variable.index)\n",
    "# # micro_variable[[\"Competitiveness region 0\", \"Competitiveness region 1\", \"Competitiveness export\"]] = pd.DataFrame(micro_variable.Competitiveness.to_list(), index=micro_variable.index)\n",
    "# # micro_variable[[\"MS region 0\", \"MS region 1\", \"MS export\"]] = pd.DataFrame(micro_variable.Ms.to_list(), index=micro_variable.index)\n",
    "# # micro_variable[[\"Prod A\", \"Prod B\"]] = pd.DataFrame(micro_variable.Prod.to_list(), index=micro_variable.index)\n",
    "micro_variables.append(micro_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "experiments = []\n",
    "dr_cca = micro_variable\n",
    "dr_cca['CCA'] = 'DR'\n",
    "experiments.append(dr_cca)\n",
    "dr_ins = micro_variable\n",
    "dr_ins['CCA'] = 'Ins'\n",
    "micro_variables.append(dr_cca)\n",
    "no_cca = micro_variable\n",
    "no_cca['CCA'] = 'None'\n",
    "experiments.append(no_cca)\n",
    "df_cons = pd.concat(experiments).reset_index()\n",
    "df_cons['CCA'].value_counts()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_variable['HH_in_out'] = macro_variable['HH_change'] * 0.5 * macro_variable['Households Coastal region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "macro_variable[\"LD_cap_0\"].plot()\n",
    "macro_variable[\"LD_cons_0\"].plot()\n",
    "macro_variable[\"LD_serv_0\"].plot()\n",
    "micro_variable.reset_index().loc[micro_variable['Step'] == 230]['Total_damage'].sum()\n",
    "micro_variable.reset_index().groupby(['AgentID'])['Repair_exp'].max().sum()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#macro_variable['HH_change'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.log(macro_variable['Av_income_pp'].iloc[10:]).pct_change().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#macro_variable['HH_in_out'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cons_hh = micro_variable[micro_variable['Type'] == 'Household']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cons_hh['number'] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(data = df_cons_hh, x='Step', y= 'number', estimator='sum' ,hue='CCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df_cons_hh, x='Step', y= 'number', estimator='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable['number'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_average = micro_variable.groupby(['Step'])['Wage','Net_worth','Price' ].mean().reset_index()\n",
    "grouped_sum = micro_variable.groupby(['Step'])['Production_made','Investment', 'number' , 'Cons' ].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = np.log(grouped_average['Price'])\n",
    "wage = np.log(grouped_average['Wage'])\n",
    "infl = np.log(grouped_average['Price'].pct_change())\n",
    "inv = np.log(grouped_sum['Investment'])\n",
    "cons = np.log(grouped_sum['Cons'])\n",
    "output = np.log(grouped_sum['Production_made'])\n",
    "unem = np.log(macro_variable['Unemployment rate coastal'])\n",
    "corr_list  = [  unem, infl,  price , inv , cons ,output ]\n",
    "df_corr = pd.concat(corr_list, axis = 1)\n",
    "df_corr.columns = [  'Unemployment', 'Infl.','Price',  'Inv',  'Cons','Output']\n",
    "#corrMatrix = df_corr.corr(method='pearson')\n",
    "corrMatrix = df_corr.corr(method='pearson')\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(figsize=(6, 6)) \n",
    "mask = np.zeros_like(corrMatrix.corr())\n",
    "mask[np.triu_indices_from(mask)] = 1\n",
    "sns.heatmap(corrMatrix, mask= mask, ax= ax, annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "gdp = np.log(grouped_sum['Production_made'] + 1)\n",
    "inv = np.log(grouped_sum['Investment'] + 1)\n",
    "cons =  np.log(grouped_sum['Cons'] + 1)\n",
    "\n",
    "bp = pd.concat([gdp, inv, cons], axis = 1)\n",
    "bp = bp.iloc[50:]\n",
    "bp.columns = ['GDP', 'INV', 'CONS']\n",
    "print(bp)\n",
    "#cycles = sm.tsa.filters.bkfilter(bp[['INV','CONS', 'GDP']], 6, 32, 12)\n",
    "cycles = sm.tsa.filters.bkfilter(bp[['INV','CONS', 'GDP']], 6, 32, 12)\n",
    "\n",
    "cycles, cf_trend = sm.tsa.filters.cffilter(bp[['INV','CONS', 'GDP']])\n",
    "# / abs(cycles['INV_cycle'].mean())\n",
    "\n",
    "cycles.columns = ['Investment', 'Consumption', 'Output']\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "ax = fig.add_subplot(111)\n",
    "cycles.plot(ax=ax, style=['r--','b-'])\n",
    "plt.legend(fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_bp_gdp = cycles['Output'].std() #/ abs(cycles['GDP_cycle'].mean()) \n",
    "std_bp_cons =  cycles['Consumption'].std()# / abs(cycles['CONS_cycle'].mean())\n",
    "std_bp_inv =  cycles['Investment'].std()\n",
    "std_bp_gdp, std_bp_cons, std_bp_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df_cons_hh, x='Step', y= 'Wage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "df_cons_hh['Total_expenditure'] = df_cons_hh['Repair_exp'] + df_cons_hh['Cons']\n",
    "sns.lineplot(data = df_cons, x = 'Step', y = 'Production_made', hue = 'CCA')\n",
    "sns.lineplot(data = df_cons_hh, x = 'Step', y = 'Total_expenditure', hue = 'CCA')\n",
    "sns.lineplot(data = df_cons_hh, x = 'Step', y = 'Net_worth', hue = 'CCA')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_variable.iloc[50:].loc[macro_variable['Unemployment rate coastal'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_variable['Unemployment rate coastal'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_variable['Unemployment rate coastal']  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"/Users/ataberna/Documents/IIASA/Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_df = pd.concat(micro_variables)\n",
    "micro_df = micro_df.reset_index(level=[\"Step\"])\n",
    "micro_df = micro_df.reset_index(level= 'AgentID')\n",
    "micro_df = micro_df.reset_index()\n",
    "#micro_df.to_csv(results_path + \"/micro_variables\")\n",
    "macro = pd.concat(macro_variables)\n",
    "#macro_variable.to_csv(results_path + \"/macro_variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firms_df = micro_df.loc[micro_df['Type'] != 'Household']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = firms_df.loc[firms_df['Step'] == 300], x = 'Size', hue = 'Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firms_df.loc[firms_df['Step'] == 30]['Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_300_df_cap = firms_df.loc[(firms_df['Step'] == 250) & (firms_df['Type'] == 'Cap')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_300_df_cap.loc[step_300_df_cap['Price'] == step_300_df_cap['Price'].max()]\n",
    "#step_300_df_cap['Price_q'] = step_300_df_cap['Price'] * step_300_df_cap['Production_made']\n",
    "#step_300_df_cap['Price'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(data= firms_df, x = 'Step', y = 'Price', hue = 'Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= micro_df, x = 'Step', y = 'Production_made', hue = 'Type',  estimator='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firms_df['number'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_df_sub_floods_grouped_sum = firms_df.groupby(['Step', 'Type'])['Production_made','Net_worth', 'number'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= firms_df, x = 'Step', y = 'number',  style= 'Type', estimator='sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= firms_df, x = 'Step', y = 'Net_worth', hue = 'Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable = model.datacollector.get_agent_vars_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable = micro_variable.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable.loc[(micro_variable['Type'] == 'Household') & (micro_variable['Step'] == 190)]['Insured'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable.loc[(micro_variable['Type'] != 'Household') & (micro_variable['Step'] == 190)]['Insured'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_df['number'] = 1\n",
    "micro_variable['number'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable_risk = micro_variable.loc[micro_variable['At_risk'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_micro_variable_risk = micro_variable_risk.loc[micro_variable_risk['Step'] == 190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_dry =  final_micro_variable_risk['Dry_proofed'].value_counts()\n",
    "tot_dry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_wet =  final_micro_variable_risk['Wet_proofed'].value_counts()\n",
    "tot_wet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_elev =  final_micro_variable_risk['Elevated'].value_counts()\n",
    "tot_elev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable_ins = micro_variable.loc[micro_variable['Premium'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_micro_variable_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_ins =  micro_variable_ins['Insured'].value_counts()\n",
    "tot_ins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cca  ={ 'Insurance' :tot_ins[1] / (tot_ins[0] + tot_ins[1]),\n",
    "            'Dry proofing' : tot_dry[1] / (tot_dry[0] + tot_dry[1]),\n",
    "            'Wet proofing' : tot_wet[1] / (tot_wet[0] + tot_wet[1]),\n",
    "            'Elevation' : tot_elev[1] / (tot_elev[0] + tot_elev[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cca_df = pd.Series(tot_cca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tot_cca_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['science','no-latex','ieee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cca_df_no_sub = pd.read_csv('tot_cca_df_no_sub')\n",
    "tot_cca_df_no_sub = tot_cca_df_no_sub.rename(columns = {'Unnamed: 0': 'CCA', '0': 'rate'})\n",
    "tot_cca_df_no_sub = tot_cca_df_no_sub.set_index('CCA')\n",
    "tot_cca_df_no_sub['CCA_sub'] = tot_cca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( 1,1, figsize = (4,4))\n",
    "palette_1 = sns.color_palette(\"colorblind\", 4)\n",
    "labels = list(tot_cca_df.index)\n",
    "\n",
    "sns.barplot(data = tot_cca_df_no_sub, x= list(tot_cca_df_no_sub.index), y = 'CCA_sub', color = 'gray', label= 'CCA uptake with subsidy')\n",
    "sns.barplot(data = tot_cca_df_no_sub, x=  list(tot_cca_df_no_sub.index), y = 'rate', palette=palette_1 )\n",
    "#axes.set_xticklabels( labels = list(reversed(tot_cca_df.index)) ,rotation=-1)\n",
    "plt.legend()\n",
    "axes.set_title('Expected sdaptation actions uptake in 2050')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable_hh = micro_variable.loc[micro_variable['Type'] == 'Household']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable_hh['Dry_proofed'].value_counts()[1] / (micro_variable_hh['Dry_proofed'].value_counts()[0] + micro_variable_hh['Dry_proofed'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable_hh['Wet_proofed'].value_counts()[1] / (micro_variable_hh['Wet_proofed'].value_counts()[0] + micro_variable_hh['Wet_proofed'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable_hh['Elevated'].value_counts()[1] / (micro_variable_hh['Elevated'].value_counts()[0] + micro_variable_hh['Elevated'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable_hh['Insured'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#micro_variable.loc[micro_variable['Type'] != ['Household']]['Insured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable['Insured'].value_counts()[1] / (micro_variable['Insured'].value_counts()[0] + micro_variable['Insured'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variables = micro_variable_hh.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = micro_variables.groupby(['Step'])['number','Elevated', 'Wet_proofed', 'Dry_proofed'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Ratio_elevated'] = a['Elevated'] / a['number']\n",
    "a['Ratio_wet'] = a['Wet_proofed'] / a['number']\n",
    "a['Ratio_dry'] = a['Dry_proofed'] / a['number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = a, x= 'Step', y = 'Ratio_elevated')\n",
    "sns.lineplot(data = a, x= 'Step', y = 'Ratio_wet')\n",
    "sns.lineplot(data = a, x= 'Step', y = 'Ratio_dry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sns.lineplot(data= micro_df.loc[micro_df['Type'] != 'Household'], x = 'Step', y = 'number',  style= 'Type', estimator='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_variable['Unemployment rate coastal'].iloc[15:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= micro_df, x = 'Step', y = 'Production_made', hue = 'Type',  estimator='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= micro_df, x = 'Step', y = 'Net_worth', hue = 'Type')\n",
    "#sns.lineplot(data= micro_df.loc[micro_df['Type'] != 'Cap'], x = 'Step', y = 'Net_worth', hue = 'Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variable \n",
    "stop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['At_risk', 'Education', 'Step', 'AgentID', 'Damage_coeff', 'House_value', 'Wage', 'Net worth','Monetary_damage' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path =  \"/Users/ataberna/Documents/PNAS/Results/test_homo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variables_pmt_int_hom = pd.read_csv(results_path + '/micro_cca_2_floods_pmt_hom_t', usecols= variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variables_eu_hom = pd.read_csv(results_path + '/micro_2floods_eu_hom',  usecols= variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variables_no_cca_hom = pd.read_csv(results_path + '/micro_cca_2_floods_no_hom_t',  usecols= variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variables_eu_hom = micro_variables_pmt_int_hom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_dfs_homo = [micro_variables_no_cca_hom, micro_variables_eu_hom, micro_variables_pmt_int_hom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_variables_pmt_int = pd.read_csv(results_path + '/micro_cca_2_floods_pmt_het_t',  usecols= variables)\n",
    "micro_variables_pmt_int_no_floods = pd.read_csv(results_path + '/micro_pmt_cca_no_floods',  usecols= variables)\n",
    "micro_variables_eu = pd.read_csv(results_path + '/micro_eu_cca_2_floods',  usecols= variables)\n",
    "micro_variables_eu_no_floods = pd.read_csv(results_path + '/micro_eu_cca_no_floods',  usecols= variables)\n",
    "micro_variables_no_cca = pd.read_csv(results_path + '/micro_no_cca_2_floods',  usecols= variables)\n",
    "micro_variables_no_floods = pd.read_csv(results_path + '/micro_no_cca_no_floods',  usecols= variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_dfs = [micro_variables_no_floods, micro_variables_no_cca,micro_variables_eu_no_floods ,micro_variables_eu, micro_variables_pmt_int_no_floods, micro_variables_pmt_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_dfs[5]['Education'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theories = ['No adaptation', 'No adaptation', 'EU', 'EU', 'PMT', 'PMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risk_df_list = []\n",
    "at_risk_df_list_homo = []\n",
    "homo = 0 \n",
    "for i in range(len(micro_dfs)):\n",
    "    at_risk_df =  micro_dfs[i].loc[(micro_dfs[i]['At_risk'] == True) & (micro_dfs[i]['Education'] != 1) & (micro_dfs[i]['Step'] >1 ) &  (micro_dfs[i]['AgentID'] % 10 == 0) ]# & (datasets[i]['Flooded'] == True)]\n",
    "    at_risk_df['Theory'] = theories[i]\n",
    "    if i % 2 == 0:\n",
    "    \n",
    "        at_risk_df_homo =  micro_dfs_homo[homo].loc[(micro_dfs_homo[homo]['At_risk'] == True) & (micro_dfs_homo[homo]['Education'] != 1) & (micro_dfs_homo[homo]['Step'] >1 ) &  (micro_dfs_homo[homo]['AgentID'] % 10 == 0) ]\n",
    "        at_risk_df_homo['Theory'] = theories[homo]\n",
    "        at_risk_df_list_homo.append(at_risk_df_homo)\n",
    "\n",
    "        homo += 1\n",
    "    #at_risk_df['Education'] = at_risk_df['Education'] - 1\n",
    "    at_risk_df_list.append(at_risk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['science','no-latex','ieee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risk_df_list[1]['Education'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = ['solid', (0, (3, 10, 1, 10)), 'dotted']\n",
    "palette_1 = sns.color_palette(\"colorblind\", 3)\n",
    "font = 11\n",
    "fig, axes = plt.subplots( 1,1, sharey = True, figsize = (7,7))\n",
    "a =  0\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    if i %2 == 0:\n",
    "\n",
    "       legend = False\n",
    "       sns.lineplot(at_risk_df_list[i + 1]['Step'], at_risk_df_list[i + 1]['Damage_coeff'], hue = at_risk_df_list[i + 1]['Education'], palette =palette_1, ci=95, linestyle = linestyles[a], legend=legend )\n",
    "\n",
    "       a += 1\n",
    "plt.plot(0,0, label = \"Secondary\", linestyle =linestyles[0], color = palette_1[0] )\n",
    "plt.plot(0,0, label = \"Tertiary\", linestyle =linestyles[0], color = palette_1[1] )\n",
    "plt.plot(0,0, label = \"Post-grad\", linestyle =linestyles[0], color = palette_1[2] )\n",
    "plt.plot(0,0, label = \"No adaptation - Heterogenous\", linestyle =linestyles[0], color = 'black' )\n",
    "plt.plot(0,0, label = \"EU - Heterogenous\", linestyle =linestyles[1], color = 'black' )\n",
    "plt.plot(0,0, label = \"Extended PMT - Heterogenous\", linestyle =linestyles[2], color = 'black' )\n",
    "plt.axvline(x = 100, linestyle = 'dashed')\n",
    "plt.axvline(x = 140, linestyle = 'dashed')\n",
    "plt.ylabel('Average damage coefficient', fontsize = font)\n",
    "plt.xlabel('Step', fontsize = font)\n",
    "plt.legend( loc = 'best', fontsize = font -1)\n",
    "       #sns.lineplot(at_risk_df_list[i + 1]['Step'], at_risk_df_list[i + 1]['Elevated'], hue = at_risk_df_list[i + 1]['Education'], ci = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = ['solid', (0, (3, 10, 1, 10)), 'dotted']\n",
    "palette_1 = sns.color_palette(\"colorblind\", 3)\n",
    "font = 11\n",
    "fig, axes = plt.subplots( 1,1, sharey = True, figsize = (7,7))\n",
    "a =  0\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    if i %2 == 0:\n",
    "\n",
    "       legend = False\n",
    "       sns.lineplot(at_risk_df_list[i + 1]['Step'], at_risk_df_list[i + 1]['Damage_coeff'] * at_risk_df_list[i + 1]['House_value'] / at_risk_df_list[i + 1]['Wage'] , hue = at_risk_df_list[i + 1]['Education'], palette =palette_1, ci=95, linestyle = linestyles[a], legend=legend )\n",
    "       sns.lineplot(at_risk_df_list_homo[a]['Step'], at_risk_df_list_homo[a]['Damage_coeff'] * at_risk_df_list_homo[a]['House_value'] / at_risk_df_list_homo[a]['Wage'], color = 'darkred', ci=95, linestyle = linestyles[a] )\n",
    "\n",
    "       a += 1\n",
    "plt.plot(0,0, label = \"Low adaptive capacity\", linestyle =linestyles[0], color = palette_1[0] )\n",
    "plt.plot(0,0, label = \"Medium adaptive capacity\", linestyle =linestyles[0], color = palette_1[1] )\n",
    "plt.plot(0,0, label = \"High adaptive capacity\", linestyle =linestyles[0], color = palette_1[2] )\n",
    "plt.plot(0,0, label = \"Homogenous adaptive capacity\", linestyle =linestyles[0], color = 'darkred' )\n",
    "plt.plot(0,0, label = \"No adaptation - Heterogenous\", linestyle =linestyles[0], color = 'black' )\n",
    "plt.plot(0,0, label = \"EU - Heterogenous\", linestyle =linestyles[1], color = 'black' )\n",
    "plt.plot(0,0, label = \"Extended PMT - Heterogenous\", linestyle =linestyles[2], color = 'black' )\n",
    "plt.axvline(x = 100, linestyle = 'dashed')\n",
    "plt.axvline(x = 140, linestyle = 'dashed')\n",
    "plt.ylabel('Potential damage normalized by income', fontsize = font)\n",
    "plt.xlabel('Step', fontsize = font)\n",
    "plt.legend( loc = 'best',bbox_to_anchor=(0.5, 0.6), fontsize = font -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risk_df_list_homo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = ['solid', (0, (3, 10, 1, 10)), 'dotted']\n",
    "palette_1 = sns.color_palette(\"colorblind\", 3)\n",
    "palette_2 = sns.color_palette(\"colorblind\", 1)\n",
    "font = 11\n",
    "fig, axes = plt.subplots( 1,2, sharey = True, figsize = (10,5))\n",
    "a =  0\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    if i %2 == 0 and i < 2:\n",
    "\n",
    "       legend = False\n",
    "       sns.stackplot()\n",
    "       #sns.lineplot(at_risk_df_list[i + 1]['Step'], at_risk_df_list[i + 1]['Damage_coeff'] * at_risk_df_list[i + 1]['House_value'] / at_risk_df_list[i + 1]['Wage'] , hue = at_risk_df_list[i + 1]['Education'], palette =palette_1, ci=95, linestyle = linestyles[a], legend=legend, ax= axes[0] )\n",
    "       #sns.lineplot(at_risk_df_list_homo[a]['Step'], at_risk_df_list_homo[a]['Damage_coeff'] * at_risk_df_list_homo[a]['House_value'] / at_risk_df_list_homo[a]['Wage'], palette =palette_2, ci=95, linestyle = linestyles[a], legend=legend, ax= axes[0] )\n",
    "       axes[0].axvline(x = 100, linestyle = 'dashed')\n",
    "       axes[0].axvline(x = 140, linestyle = 'dashed')\n",
    "       a += 1\n",
    "    if i %2 == 0 and i >= 2:\n",
    "       legend = False\n",
    "       sns.lineplot(at_risk_df_list[i + 1]['Step'], at_risk_df_list[i + 1]['Damage_coeff'] * at_risk_df_list[i + 1]['House_value'] / at_risk_df_list[i + 1]['Wage'] , hue = at_risk_df_list[i + 1]['Education'], palette =palette_1, ci=95, linestyle = linestyles[a], legend=legend, ax= axes[1] )\n",
    "       sns.lineplot(at_risk_df_list_homo[a]['Step'], at_risk_df_list_homo[a]['Damage_coeff'] * at_risk_df_list_homo[a]['House_value'] / at_risk_df_list_homo[a]['Wage'], palette =palette_2, ci=95, linestyle = linestyles[a], legend=legend, ax= axes[1] )\n",
    "       axes[1].axvline(x = 100, linestyle = 'dashed')\n",
    "       axes[1].axvline(x = 140, linestyle = 'dashed')\n",
    "       a += 1\n",
    "plt.plot(0,0, label = \"Low adaptive capacity\", linestyle =linestyles[0], color = palette_1[0] )\n",
    "plt.plot(0,0, label = \"Medium adaptive capacity\", linestyle =linestyles[0], color = palette_1[1] )\n",
    "plt.plot(0,0, label = \"High adaptive capacity\", linestyle =linestyles[0], color = palette_1[2] )\n",
    "plt.plot(0,0, label = \"No adaptation - Heterogenous\", linestyle =linestyles[0], color = 'black' )\n",
    "plt.plot(0,0, label = \"EU - Heterogenous\", linestyle =linestyles[1], color = 'black' )\n",
    "plt.plot(0,0, label = \"Extended PMT - Heterogenous\", linestyle =linestyles[2], color = 'black' )\n",
    "\n",
    "axes[0].set_ylabel('Potential damage normalized by income', fontsize = font)\n",
    "plt.xlabel('Step', fontsize = font)\n",
    "plt.legend( loc = 'best', fontsize = font -1)\n",
    "\n",
    "#,bbox_to_anchor=(0.5, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_big = pd.concat([at_risk_df_list[1], at_risk_df_list[3], at_risk_df_list[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = dataset_big.loc[dataset_big['Theory'] == 'No adaptation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Low', 'Med', 'High']\n",
    "linestyles = ['solid', (0, (3, 10, 1, 10)), 'dotted']\n",
    "palette_1 = sns.color_palette(\"colorblind\", 3)\n",
    "font = 11\n",
    "fig, axes = plt.subplots( 1,3, sharey = True, figsize = (15,5))\n",
    "a =  0\n",
    "for i in range(3):\n",
    "   # if i %2 == 0:\n",
    "       dataset_trial = dataset_big.loc[dataset_big['Education'] == a + 2]\n",
    "       dataset_no_cca = dataset_trial.loc[dataset_trial['Theory'] == 'No adaptation']\n",
    "       legend = False\n",
    "       sns.lineplot(dataset_trial['Step'],  (dataset_trial['Damage_coeff'] * dataset_trial['House_value'] / dataset_trial['Wage']) , hue = dataset_trial['Theory'], palette =palette_1, ci=95, linestyle = 'solid', legend=legend, ax = axes[a] )\n",
    "       # sns.lineplot(dataset_no_cca['Step'],  (dataset_no_cca['Damage_coeff'] * dataset_no_cca['House_value'] / dataset_no_cca['Wage']) , hue = dataset_trial['Theory'], palette =palette_1, ci=95, linestyle = 'solid', legend=legend, ax = axes[a] )\n",
    "       axes[a].axvline(x = 100, linestyle = 'solid')\n",
    "       axes[a].axvline(x = 140, linestyle = 'solid')\n",
    "       axes[a].axhline(y = 0, linestyle = 'dotted')\n",
    "       axes[a].set_title(titles[a], fontsize = font + 3)\n",
    "       axes[0].set_ylabel('Damage reduction normalized by income', fontsize = font + 2)\n",
    "       axes[a].set_xlabel('Step', fontsize = font + 2)\n",
    "       a += 1\n",
    "#plt.plot(0,0, label = \"Low adaptive capacity\", linestyle =linestyles[0], color = palette_1[0] )\n",
    "#plt.plot(0,0, label = \"Medium adaptive capacity\", linestyle =linestyles[0], color = palette_1[1] )\n",
    "#plt.plot(0,0, label = \"High adaptive capacity\", linestyle =linestyles[0], color = palette_1[2] )\n",
    "#plt.plot(0,0, label = \"No adaptation - Heterogenous\", linestyle =linestyles[0], color = 'black' )\n",
    "#plt.plot(0,0, label = \"EU - Heterogenous\", linestyle =linestyles[1], color = 'black' )\n",
    "#plt.plot(0,0, label = \"Extended PMT - Heterogenous\", linestyle =linestyles[2], color = 'black' )\n",
    "\n",
    "plt.ylabel('Potential damage normalized by income', fontsize = font)\n",
    "plt.xlabel('Step', fontsize = font)\n",
    "plt.legend( loc = 'best',bbox_to_anchor=(0.5, 0.6), fontsize = font -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_at_risk_df_list = []\n",
    "red_at_risk_df_list_homo = []\n",
    "homo = 0\n",
    "for i in range(len(micro_dfs)):\n",
    "    at_risk_df =  micro_dfs[i].loc[(micro_dfs[i]['At_risk'] == True) & (micro_dfs[i]['Education'] != 1) & (micro_dfs[i]['Step'] > 95) &  (micro_dfs[i]['Step'] < 200) &  (micro_dfs_homo[i]['AgentID'] % 10 == 0)]# & (datasets[i]['Flooded'] == True)]\n",
    "    #at_risk_df['Theory'] = theories[i]\n",
    "    red_at_risk_df_list.append(at_risk_df)\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "\n",
    "        at_risk_df_homo =  micro_dfs_homo[homo].loc[(micro_dfs_homo[homo]['At_risk'] == True) & (micro_dfs_homo[homo]['Education'] != 1) & (micro_dfs_homo[homo]['Step'] >1 ) & (micro_dfs[i]['Step'] > 95) &  (micro_dfs[i]['Step'] < 200) &  (micro_dfs_homo[homo]['AgentID'] % 10 == 0) ]\n",
    "        #at_risk_df_homo['Theory'] = theories[homo]\n",
    "        red_at_risk_df_list_homo.append(at_risk_df_homo)\n",
    "\n",
    "        homo+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = ['solid', (0, (3, 10, 1, 10)), 'dotted']\n",
    "palette_1 = sns.color_palette(\"colorblind\", 3)\n",
    "font = 11\n",
    "fig, axes = plt.subplots( 1,1, sharey = True, figsize = (7,7))\n",
    "sns.barplot(  data = red_at_risk_df_list[0] , y = red_at_risk_df_list[0]['House_wage_ratio'], x = red_at_risk_df_list[0][\"Education\"], palette =palette_1)\n",
    "plt.plot(0,0, label = \"Low adaptive capacity\", linestyle =linestyles[0], color = palette_1[0] )\n",
    "plt.plot(0,0, label = \"Medium adaptive capacity\", linestyle =linestyles[0], color = palette_1[1] )\n",
    "plt.plot(0,0, label = \"High adaptive capacity\", linestyle =linestyles[0], color = palette_1[2] )\n",
    "plt.ylabel('Av. House value normalized by income', fontsize = font + 2)\n",
    "plt.xlabel('Education level', fontsize = font + 2)\n",
    "plt.xticks([])\n",
    "plt.legend( loc = 'best',bbox_to_anchor=(0.25, 0.6), fontsize = font -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['No adaptation - Heterogenous', 'EU - Heterogenous', 'Extended PMT - Heterogenous']\n",
    "linestyles = ['solid', (0, (3, 10, 1, 10)), 'dotted']\n",
    "palette_1 = sns.color_palette(\"colorblind\", 3)\n",
    "font = 11\n",
    "fig, axes = plt.subplots( 1,3, figsize = (15,5))\n",
    "a =  0\n",
    "for i in range(len(red_at_risk_df_list)):\n",
    "    if i %2 == 0:\n",
    "       print(i)\n",
    "       legend = False\n",
    "       sns.lineplot(red_at_risk_df_list_homo[a]['Step'], (red_at_risk_df_list_homo[a]['Net worth']- red_at_risk_df_list_homo[a]['Monetary_damage'])/red_at_risk_df_list_homo[a]['Wage'],linestyle = 'solid' ,palette ='darkred', ci=95, legend=legend, ax= axes[a])\n",
    "       sns.lineplot(red_at_risk_df_list[i + 1]['Step'], (red_at_risk_df_list[i + 1]['Net worth']- red_at_risk_df_list[i + 1]['Monetary_damage'])/red_at_risk_df_list[i + 1]['Wage'], hue = red_at_risk_df_list[i + 1]['Education'],linestyle = 'solid' ,palette =palette_1, ci=95, legend=legend, ax= axes[a])\n",
    "       sns.lineplot(red_at_risk_df_list[i]['Step'], (red_at_risk_df_list[i]['Net worth']- red_at_risk_df_list[i]['Monetary_damage'])/red_at_risk_df_list[i]['Wage'], hue = red_at_risk_df_list[i]['Education'], palette =palette_1, ci=None, linestyle = 'dashed', legend=legend, ax= axes[a])\n",
    "       axes[a].axvline(x = 100, linestyle = 'solid')\n",
    "       axes[a].axvline(x = 140, linestyle = 'solid')\n",
    "       axes[a].axhline(y = 0, linestyle = 'dotted')\n",
    "       axes[a].set_title(titles[a], fontsize = font + 3)\n",
    "       axes[0].set_ylabel('Liquid resources to wage ratio', fontsize = font + 2)\n",
    "       axes[a].set_xlabel('Step', fontsize = font + 2)\n",
    "       if a > 0:\n",
    "           axes[a].set_ylim([-1, 10])\n",
    "\n",
    "       a += 1\n",
    "\n",
    "\n",
    "plt.plot(100,0, label = \"Low adaptive capacity\", linestyle =linestyles[0], color = palette_1[0] )\n",
    "plt.plot(100,0, label = \"Medium adaptive capacity\", linestyle =linestyles[0], color = palette_1[1] )\n",
    "plt.plot(100,0, label = \"High adaptive capacity\", linestyle =linestyles[0], color = palette_1[2] )\n",
    "plt.plot(100,0, label = \"Homogenous adaptive capacity\", linestyle =linestyles[0], color = 'darkred' )\n",
    "plt.plot(100,0, label = \"Two floods\", linestyle ='solid', color = 'black' )\n",
    "plt.plot(100,0, label = \"Zero liquid resources\", linestyle ='dotted', color = 'black' )\n",
    "plt.plot(100,0, label = \"Counterfactual\" \"\\n\" \"with no floods\", linestyle ='dashed', color = 'black' )\n",
    "\n",
    "#plt.plot(0,0, label = \"No adaptation\", linestyle =linestyles[0], color = 'black' )\n",
    "#plt.plot(0,0, label = \"Expected utility (EU)\", linestyle =linestyles[1], color = 'black' )\n",
    "#plt.plot(0,0, label = \"Protection Motivation Theory (PMT) \", linestyle =linestyles[2], color = 'black' )\n",
    "\n",
    "\n",
    "plt.legend( loc='center', bbox_to_anchor =(-0.5, 0.2), fontsize = font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risk_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( 1,3, sharey = True, figsize = (15,6))\n",
    "a =  0\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    if i %2 == 0:\n",
    "       legend = False \n",
    "       sns.lineplot(at_risk_df_list[i + 1]['Step'], (at_risk_df_list[i + 1]['Net worth']- at_risk_df_list[i + 1]['Monetary_damage'])/at_risk_df_list[i + 1]['House_wage_ratio'], hue = at_risk_df_list[i + 1]['Education'], ax= axes[a])\n",
    "       sns.lineplot(at_risk_df_list[i]['Step'], (at_risk_df_list[i]['Net worth']- at_risk_df_list[i]['Monetary_damage'])/at_risk_df_list[i]['House_wage_ratio'], hue = at_risk_df_list[i]['Education'],linestyle = '--', ax= axes[a])\n",
    "       a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( 1,3, sharey = True, figsize = (15,6))\n",
    "a =  0\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    if i %2 == 0:\n",
    "       legend = False \n",
    "       sns.lineplot(at_risk_df_list[i + 1]['Step'], (at_risk_df_list[i + 1]['Net worth']- at_risk_df_list[i + 1]['Monetary_damage'])/at_risk_df_list[i + 1]['House_wage_ratio'], hue = at_risk_df_list[i + 1]['Education'], ax= axes[a])\n",
    "       sns.lineplot(at_risk_df_list[i]['Step'], (at_risk_df_list[i]['Net worth']- at_risk_df_list[i]['Monetary_damage'])/at_risk_df_list[i]['House_wage_ratio'], hue = at_risk_df_list[i]['Education'],linestyle = '--', ax= axes[a])\n",
    "       a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( 2,2, sharey = True, figsize = (10,10))\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    j = 0\n",
    "    legend = True\n",
    "    if i > 1:\n",
    "        j = 1\n",
    "    if i > 0:   \n",
    "       legend = False\n",
    "       sns.lineplot(at_risk_df_list[i]['Step'], (at_risk_df_list[i]['Net worth']- at_risk_df_list[i]['Monetary_damage']), hue = at_risk_df_list[i]['Education'], ax= axes[i%2][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop\n",
    "\n",
    "sns.lineplot(df_flooded['Step'], df_flooded['Monetary_damage']/ df_flooded['House_wage_ratio'], hue = df_flooded['Education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node_label = [\"A1\", \"A2\", \"A3\", \"A4\",\"A5\", \"B1\", \"B2\",\"B3\", \"B4\", \"B5\",\"C1\", \"C2\", \"C3\", \"C4\",\"C5\" ]\n",
    "node_dict = {y:x for x, y in enumerate(node_label)}\n",
    "node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source = []\n",
    "for i in range(51):\n",
    "    if i < 5:\n",
    "        source.append('A1')\n",
    "    elif i > 5 and i <=10:\n",
    "        source.append('A2')\n",
    "    elif i > 10 and i <= 15:\n",
    "        source.append('A3')\n",
    "    elif i > 15 and i <= 20:\n",
    "        source.append('A4')\n",
    "    elif i > 20 and i <= 25:\n",
    "        source.append('A5')\n",
    "    elif i > 25 and i <= 30:\n",
    "        source.append('B1')\n",
    "    elif i > 30 and i <=35:\n",
    "        source.append('B2')\n",
    "    elif i > 35 and i <= 40:\n",
    "        source.append('B3')\n",
    "    elif i > 40 and i <= 45:\n",
    "        source.append('B4')\n",
    "    elif i > 45 and i <= 50:\n",
    "        source.append('A5')\n",
    "\n",
    "\n",
    "target_1 = []\n",
    "for i in range(25):\n",
    "    if i % 5 == 0:\n",
    "        target_1.append('B1')\n",
    "    elif i%5 == 1:\n",
    "        target_1.append('B2')\n",
    "    elif i%5 == 2:\n",
    "        target_1.append('B3')\n",
    "    elif i%5 == 3:\n",
    "        target_1.append('B4')\n",
    "    elif i%5 == 4:\n",
    "        target_1.append('B5')\n",
    "target_2 = []\n",
    "for i in range(25):\n",
    "    if i % 5 == 0:\n",
    "        target_2.append('C1')\n",
    "    elif i%5 == 1:\n",
    "        target_2.append('C2')\n",
    "    elif i%5 == 2:\n",
    "        target_2.append('C3')\n",
    "    elif i%5 == 3:\n",
    "        target_2.append('C4')\n",
    "    elif i%5 == 4:\n",
    "        target_2.append('C5')   \n",
    "\n",
    "#target = ['B1','B2','B3','B1','B2','B3','C1','C1','C2','C1','C2'] \n",
    "#values = [ 10, 5, 15, 5, 20, 45, 15, 20, 5, 30, 30 ]\n",
    "target = target_1 + target_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(target)\n",
    "df_2 = pd.DataFrame(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target), len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_flood_df_list = []\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    pre_flood_df =  at_risk_df_list[i].loc[at_risk_df_list[i]['Step'] == 99]\n",
    "    pre_flood_df['Quintile_pre_flood'] = None\n",
    "    pre_flood_df_list.append(pre_flood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quintiles_list = []\n",
    "for i in range(len(pre_flood_df_list)):\n",
    " #+ benchmark['House_wage_ratio'] \n",
    "    quintiles = pre_flood_df_list[i]['Net worth'].quantile([0.2,0.4,0.6,0.8])\n",
    "    quintiles_list.append(quintiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_quintiles_list = []\n",
    "for i in range(len(pre_flood_df_list)):\n",
    "    dataset = pre_flood_df_list [i]\n",
    "    variable = 'Quintile_pre_flood'\n",
    "    variable_2 ='Net worth'\n",
    "    a = quintiles_list[i]\n",
    "    for x,line in dataset.iterrows():\n",
    "    # print(x)\n",
    "        if line[variable_2] <= a.iloc[0]:\n",
    "            dataset[variable][x] = 1\n",
    "        elif line[variable_2] > a.iloc[0] and line[variable_2] <= a.iloc[1] :\n",
    "            dataset[variable][x] = 2\n",
    "        elif line[variable_2] > a.iloc[1] and line[variable_2] <= a.iloc[2] :\n",
    "            dataset[variable][x] = 3\n",
    "        elif line[variable_2] > a.iloc[2] and line[variable_2] <= a.iloc[3] :\n",
    "            dataset[variable][x] = 4\n",
    "        elif line[variable_2] > a.iloc[3] :\n",
    "            dataset[variable][x] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_flood_df_list = []\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    post_flood_df =  at_risk_df_list[i].loc[at_risk_df_list[i]['Step'] == 110]\n",
    "    post_flood_df['Quintile_post_flood'] = None\n",
    "    post_flood_df_list.append(post_flood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_2floods_df_list = []\n",
    "for i in range(len(at_risk_df_list)):\n",
    "    post_flood_df =  at_risk_df_list[i].loc[at_risk_df_list[i]['Step'] == 150]\n",
    "    post_flood_df['Quintile_post_2floods'] = None\n",
    "    post_2floods_df_list.append(post_flood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quintiles_list_post = []\n",
    "for i in range(len(post_flood_df_list)):\n",
    " #+ benchmark['House_wage_ratio'] \n",
    "    quintiles = post_flood_df_list[i]['Net worth'].quantile([0.2,0.4,0.6,0.8])\n",
    "    quintiles_list_post.append(quintiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quintiles_list_post_2 = []\n",
    "for i in range(len(post_2floods_df_list)):\n",
    " #+ benchmark['House_wage_ratio'] \n",
    "    quintiles = post_2floods_df_list[i]['Net worth'].quantile([0.2,0.4,0.6,0.8])\n",
    "    quintiles_list_post_2.append(quintiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(post_flood_df_list)):\n",
    "    dataset = post_flood_df_list [i]\n",
    "    variable = 'Quintile_post_flood'\n",
    "    variable_2 ='Net worth'\n",
    "    a = quintiles_list_post[i]\n",
    "    for x,line in dataset.iterrows():\n",
    "    # print(x)\n",
    "        if line[variable_2] <= a.iloc[0]:\n",
    "            dataset[variable][x] = 1\n",
    "        elif line[variable_2] > a.iloc[0] and line[variable_2] <= a.iloc[1] :\n",
    "            dataset[variable][x] = 2\n",
    "        elif line[variable_2] > a.iloc[1] and line[variable_2] <= a.iloc[2] :\n",
    "            dataset[variable][x] = 3\n",
    "        elif line[variable_2] > a.iloc[2] and line[variable_2] <= a.iloc[3] :\n",
    "            dataset[variable][x] = 4\n",
    "        elif line[variable_2] > a.iloc[3] :\n",
    "            dataset[variable][x] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(post_2floods_df_list)):\n",
    "    dataset = post_2floods_df_list [i]\n",
    "    variable = 'Quintile_post_2floods'\n",
    "    variable_2 ='Net worth'\n",
    "    a = quintiles_list_post_2[i]\n",
    "    for x,line in dataset.iterrows():\n",
    "    # print(x)\n",
    "        if line[variable_2] <= a.iloc[0]:\n",
    "            dataset[variable][x] = 1\n",
    "        elif line[variable_2] > a.iloc[0] and line[variable_2] <= a.iloc[1] :\n",
    "            dataset[variable][x] = 2\n",
    "        elif line[variable_2] > a.iloc[1] and line[variable_2] <= a.iloc[2] :\n",
    "            dataset[variable][x] = 3\n",
    "        elif line[variable_2] > a.iloc[2] and line[variable_2] <= a.iloc[3] :\n",
    "            dataset[variable][x] = 4\n",
    "        elif line[variable_2] > a.iloc[3] :\n",
    "            dataset[variable][x] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_2floods_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_flood_df_list[df_num] = pre_flood_df_list[df_num].set_index('AgentID')\n",
    "post_flood_df_list[df_num] = post_flood_df_list[df_num].set_index('AgentID')\n",
    "post_2floods_df_list[df_num] = post_2floods_df_list[df_num].set_index('AgentID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_flood_df_list[df_num]['Quintile_post_flood'] = post_flood_df_list[df_num]['Quintile_post_flood'] \n",
    "pre_flood_df_list[df_num]['Quintile_post_2floods'] = post_flood_df_list[df_num]['Quintile_post_2floods'] =  post_2floods_df_list[df_num]['Quintile_post_2floods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_flood_df_list[df_num] = pre_flood_df_list[df_num].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_1 = []\n",
    "values_2 = []\n",
    "pre_quint = 1\n",
    "for i in range(25):\n",
    "    \n",
    "    post_quint = 1 + i%5\n",
    "    if i > 4 and post_quint == 1:\n",
    "        pre_quint += 1\n",
    "    #if post_quint%5 == 0:\n",
    "     #   pre_quint +=1 \n",
    "    print(pre_quint, post_quint)\n",
    "    a = pre_flood_df_list[df_num].loc[(pre_flood_df_list[df_num]['Quintile_pre_flood'] == pre_quint) & (pre_flood_df_list[df_num]['Quintile_post_flood'] == post_quint)]\n",
    "    b = pre_flood_df_list[df_num].loc[(pre_flood_df_list[df_num]['Quintile_post_flood'] == pre_quint) & (pre_flood_df_list[df_num]['Quintile_post_2floods'] == post_quint)]\n",
    "    values_1.append(len(a))\n",
    "    values_2.append(len(b))\n",
    "values = values_1 + values_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from webcolors import hex_to_rgb\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_node = [node_dict[x] for x in source]\n",
    "target_node = [node_dict[x] for x in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go # Import the graphical object\n",
    "\n",
    "fig = go.Figure( \n",
    "    data=[go.Sankey( # The plot we are interest\n",
    "        # This part is for the node information\n",
    "        node = dict( \n",
    "            label = node_label\n",
    "        ),\n",
    "        # This part is for the link information\n",
    "        link = dict(\n",
    "            source = source_node,\n",
    "            target = target_node,\n",
    "            value = values\n",
    "        ))])\n",
    "\n",
    "# With this save the plots \n",
    "plot(fig,\n",
    "     image_filename='sankey_plot_1', \n",
    "     image='png', \n",
    "     image_width=1000, \n",
    "     image_height=600\n",
    ")\n",
    "# And shows the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure( \n",
    "    data=[go.Sankey( # The plot we are interest\n",
    "        # This part is for the node information\n",
    "        node = dict( \n",
    "            label = node_label\n",
    "        ),\n",
    "        # This part is for the link information\n",
    "        link = dict(\n",
    "            source = source_node,\n",
    "            target = target_node,\n",
    "            value = values\n",
    "        ))])\n",
    "\n",
    "# With this save the plots \n",
    "plot(fig,\n",
    "     image_filename='sankey_plot_1', \n",
    "     image='png', \n",
    "     image_width=1000, \n",
    "     image_height=600\n",
    ")\n",
    "# And shows the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure( \n",
    "    data=[go.Sankey( # The plot we are interest\n",
    "        # This part is for the node information\n",
    "        node = dict( \n",
    "            label = node_label\n",
    "        ),\n",
    "        # This part is for the link information\n",
    "        link = dict(\n",
    "            source = source_node,\n",
    "            target = target_node,\n",
    "            value = values\n",
    "        ))])\n",
    "\n",
    "# With this save the plots \n",
    "plot(fig,\n",
    "     image_filename='sankey_plot_1', \n",
    "     image='png', \n",
    "     image_width=1000, \n",
    "     image_height=600\n",
    ")\n",
    "# And shows the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure( \n",
    "    data=[go.Sankey( # The plot we are interest\n",
    "        # This part is for the node information\n",
    "        node = dict( \n",
    "            label = node_label\n",
    "        ),\n",
    "        # This part is for the link information\n",
    "        link = dict(\n",
    "            source = source_node,\n",
    "            target = target_node,\n",
    "            value = values\n",
    "        ))])\n",
    "\n",
    "# With this save the plots \n",
    "plot(fig,\n",
    "     image_filename='sankey_plot_1', \n",
    "     image='png', \n",
    "     image_width=1000, \n",
    "     image_height=600\n",
    ")\n",
    "# And shows the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure( \n",
    "    data=[go.Sankey( # The plot we are interest\n",
    "        # This part is for the node information\n",
    "        node = dict( \n",
    "            label = node_label\n",
    "        ),\n",
    "        # This part is for the link information\n",
    "        link = dict(\n",
    "            source = source_node,\n",
    "            target = target_node,\n",
    "            value = values\n",
    "        ))])\n",
    "\n",
    "# With this save the plots \n",
    "plot(fig,\n",
    "     image_filename='sankey_plot_1', \n",
    "     image='png', \n",
    "     image_width=1000, \n",
    "     image_height=600\n",
    ")\n",
    "# And shows the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b9afb27d9c06e180993146e4a89a0bb24ee97b84e45ffc02447800733ced9a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
